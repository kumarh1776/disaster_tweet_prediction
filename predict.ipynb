{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training & test sets as pandas dataframes\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>4127</td>\n",
       "      <td>drought</td>\n",
       "      <td>Meereen</td>\n",
       "      <td>Pizza drought is over I just couldn't anymore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>7675</td>\n",
       "      <td>panic</td>\n",
       "      <td>Elsewhere, NZ</td>\n",
       "      <td>Lose bus card.\\nPanic.\\nKind bus driver.\\nRepl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>3721</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian customs destroyed a total of 319 tons ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>6781</td>\n",
       "      <td>lightning</td>\n",
       "      <td>Elchilicitanierraversal</td>\n",
       "      <td>#NowPlaying 'The Lightning Strike' de Snow Pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5084</th>\n",
       "      <td>7251</td>\n",
       "      <td>nuclear%20disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If i tweet daily #Fukushima #Japan global nucl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>5937</td>\n",
       "      <td>hazard</td>\n",
       "      <td>Australia</td>\n",
       "      <td>#Lifestyle Û÷It makes me sickÛª: Baby clothe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>7355</td>\n",
       "      <td>obliterate</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>@klavierstuk doesn't so LVG is forced into the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>700</td>\n",
       "      <td>attacked</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>@envw98 @NickCoCoFree @JulieDiCaro @jdabe80 I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>6706</td>\n",
       "      <td>lava</td>\n",
       "      <td>Medan,Indonesia</td>\n",
       "      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>7505</td>\n",
       "      <td>oil%20spill</td>\n",
       "      <td>Las Vegas, Nevada</td>\n",
       "      <td>Refugio oil spill may have been costlier bigge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword                  location  \\\n",
       "2871  4127             drought                  Meereen    \n",
       "5378  7675               panic             Elsewhere, NZ   \n",
       "2592  3721           destroyed                       NaN   \n",
       "4765  6781           lightning  Elchilicitanierraversal    \n",
       "5084  7251  nuclear%20disaster                       NaN   \n",
       "4180  5937              hazard                 Australia   \n",
       "5156  7355          obliterate            United Kingdom   \n",
       "484    700            attacked           Los Angeles, CA   \n",
       "4716  6706                lava           Medan,Indonesia   \n",
       "5249  7505         oil%20spill         Las Vegas, Nevada   \n",
       "\n",
       "                                                   text  target  \n",
       "2871   Pizza drought is over I just couldn't anymore...       0  \n",
       "5378  Lose bus card.\\nPanic.\\nKind bus driver.\\nRepl...       0  \n",
       "2592  Russian customs destroyed a total of 319 tons ...       0  \n",
       "4765  #NowPlaying 'The Lightning Strike' de Snow Pat...       0  \n",
       "5084  If i tweet daily #Fukushima #Japan global nucl...       1  \n",
       "4180  #Lifestyle Û÷It makes me sickÛª: Baby clothe...       0  \n",
       "5156  @klavierstuk doesn't so LVG is forced into the...       0  \n",
       "484   @envw98 @NickCoCoFree @JulieDiCaro @jdabe80 I ...       0  \n",
       "4716  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0  \n",
       "5249  Refugio oil spill may have been costlier bigge...       1  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>8107</td>\n",
       "      <td>rescued</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>So @edsheeran just rescued this year's #Fusion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>286</td>\n",
       "      <td>ambulance</td>\n",
       "      <td>World</td>\n",
       "      <td>2 held with heroin in ambulance http://t.co/d9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>9720</td>\n",
       "      <td>tragedy</td>\n",
       "      <td>SÌ©te, France, (foto c.1968)</td>\n",
       "      <td>@TEDMED\\nI remember my friend Jeff Weisberg sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>6357</td>\n",
       "      <td>hostages</td>\n",
       "      <td>China</td>\n",
       "      <td>#hot  C-130 specially modified to land in a st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2338</td>\n",
       "      <td>collapse</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Technical Collapse -&amp;gt;  http://t.co/BfJB5H4t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>4190</td>\n",
       "      <td>drown</td>\n",
       "      <td>East Carolina University'19 ??</td>\n",
       "      <td>Fuck around and drown ???? https://t.co/fr5z9W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>7364</td>\n",
       "      <td>obliterate</td>\n",
       "      <td>trashcan somewhere in hell</td>\n",
       "      <td>@MilesWithTate but seeing the writers oblitera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>9138</td>\n",
       "      <td>suicide%20bomb</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>#Bestnaijamade: 16yr old PKK suicide bomber wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>6865</td>\n",
       "      <td>mass%20murder</td>\n",
       "      <td>The Three Broomsticks</td>\n",
       "      <td>Watching Murder in the First and you get the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>9312</td>\n",
       "      <td>survive</td>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>#ScienceDaily Parental experience may help cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         keyword                        location  \\\n",
       "2425  8107         rescued                      London, UK   \n",
       "83     286       ambulance                           World   \n",
       "2934  9720         tragedy    SÌ©te, France, (foto c.1968)   \n",
       "1886  6357        hostages                           China   \n",
       "719   2338        collapse                     Los Angeles   \n",
       "1273  4190           drown  East Carolina University'19 ??   \n",
       "2200  7364      obliterate      trashcan somewhere in hell   \n",
       "2744  9138  suicide%20bomb                         Nigeria   \n",
       "2041  6865   mass%20murder          The Three Broomsticks    \n",
       "2800  9312         survive                      Lima, Peru   \n",
       "\n",
       "                                                   text  \n",
       "2425  So @edsheeran just rescued this year's #Fusion...  \n",
       "83    2 held with heroin in ambulance http://t.co/d9...  \n",
       "2934  @TEDMED\\nI remember my friend Jeff Weisberg sa...  \n",
       "1886  #hot  C-130 specially modified to land in a st...  \n",
       "719   Technical Collapse -&gt;  http://t.co/BfJB5H4t...  \n",
       "1273  Fuck around and drown ???? https://t.co/fr5z9W...  \n",
       "2200  @MilesWithTate but seeing the writers oblitera...  \n",
       "2744  #Bestnaijamade: 16yr old PKK suicide bomber wh...  \n",
       "2041  Watching Murder in the First and you get the p...  \n",
       "2800  #ScienceDaily Parental experience may help cor...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Use Python stopwords dict to remove generally meaningless words\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "#PorterStemmer to truncate words to root\n",
    "def perform_stemming(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing; apply the relevant functions to both the train & test data\n",
    "train.replace('', np.nan, inplace=True)\n",
    "test.fillna(\"\", inplace=True)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(preprocess_text)\n",
    "test[\"text\"] = test[\"text\"].apply(preprocess_text)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(word_tokenize)\n",
    "test[\"text\"] = test[\"text\"].apply(word_tokenize)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(remove_stopwords)\n",
    "test[\"text\"] = test[\"text\"].apply(remove_stopwords)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(perform_stemming)\n",
    "test[\"text\"] = test[\"text\"].apply(perform_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[forest, fire, near, la, rong, sask, canada]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[resid, ask, shelter, place, notifi, offic, ev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[peopl, receiv, wildfir, evacu, order, califor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[got, sent, photo, rubi, alaska, smoke, wildfi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  [deed, reason, earthquak, may, allah, forgiv, us]   \n",
       "1   4     NaN      NaN       [forest, fire, near, la, rong, sask, canada]   \n",
       "2   5     NaN      NaN  [resid, ask, shelter, place, notifi, offic, ev...   \n",
       "3   6     NaN      NaN  [peopl, receiv, wildfir, evacu, order, califor...   \n",
       "4   7     NaN      NaN  [got, sent, photo, rubi, alaska, smoke, wildfi...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[happen, terribl, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[heard, earthquak, differ, citi, stay, safe, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[forest, fire, spot, pond, gees, flee, across,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[apocalyps, light, spokan, wildfir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0                                       [happen, terribl, car, crash]\n",
       "1   2                   [heard, earthquak, differ, citi, stay, safe, e...\n",
       "2   3                   [forest, fire, spot, pond, gees, flee, across,...\n",
       "3   9                                 [apocalyps, light, spokan, wildfir]\n",
       "4  11                            [typhoon, soudelor, kill, china, taiwan]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the text column from word tokens back into a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(lambda tokens: \" \".join(tokens))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda tokens: \" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN          deed reason earthquak may allah forgiv us   \n",
       "1   4     NaN      NaN               forest fire near la rong sask canada   \n",
       "2   5     NaN      NaN  resid ask shelter place notifi offic evacu she...   \n",
       "3   6     NaN      NaN        peopl receiv wildfir evacu order california   \n",
       "4   7     NaN      NaN  got sent photo rubi alaska smoke wildfir pour ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text column is back into a string as in raw data, except it has been preprocessed.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up TF-IDF Vectorization\n",
    "\n",
    "Use term frequency, inverse document frequency (common NLP method for text data) to capture importance of relevant words in the tweets and match to their classification (target) \\ \n",
    "\n",
    "Then use Multinomial Naive Bayes to do final classification on Training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit vocabulary to 5000 words\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# x represents the text data with a TF-IDF matrix. y holds the target labels\n",
    "x = vectorizer.fit_transform(train[\"text\"])\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorizer.fit_transform(train[\"text\"])\n",
    "y = train[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into both training & validation sets\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "\n",
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       874\n",
      "           1       0.82      0.69      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.80      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use accuracy score to evaluate Naive Bayes\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Get overall classification report to evaluate model performance\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = vectorizer.transform(test[\"text\"])\n",
    "test_predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_submission = pd.DataFrame({\"id\": test[\"id\"], \"tweet\": test[\"text\"], \"target\": test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>happen terribl car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>heard earthquak differ citi stay safe everyon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>forest fire spot pond gees flee across street ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>apocalyps light spokan wildfir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet  target\n",
       "0   0                           happen terribl car crash       1\n",
       "1   2      heard earthquak differ citi stay safe everyon       1\n",
       "2   3  forest fire spot pond gees flee across street ...       1\n",
       "3   9                     apocalyps light spokan wildfir       1\n",
       "4  11                 typhoon soudelor kill china taiwan       1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
